{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFJn4-OAiXMb"
      },
      "source": [
        "\n",
        "# Homework 2\n",
        "\n",
        "## Qingci Luo - ql2466\n",
        "\n",
        "### Due: Fri Mar 11th @ 11:59pm ET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYdomztdiXMd"
      },
      "source": [
        "In this homework we will be performing model evaluation, model selection and hyperparameter tuning in both a regression and classification setting.\n",
        "\n",
        "We will be working with a small set of home sales data as we might see on a real-estate website.\n",
        "\n",
        "\n",
        "## Instructions\n",
        "\n",
        "- Replace Name and UNI in the first cell and filename with your UNI and name.\n",
        "- Follow the comments below and fill in the blanks (____) to complete.\n",
        "- Where a text response is asked for, please enter as a comment, starting each line with #.\n",
        "\n",
        "\n",
        "Out of 50 points total."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqlB-pPDiXMe"
      },
      "source": [
        "## Part 0: Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dGkZfJIViXMe"
      },
      "outputs": [],
      "source": [
        "# 1. (2pts) Set up our environment with common libraries and plot settings.\n",
        "#    Note: generally we would do all of our imports here but some imports\n",
        "#    have been left till later where they are used.\n",
        "\n",
        "# Import numpy as np, pandas as pd, matplotlib.pyplot as plt and seaborn as sns\n",
        "# Note: use as many lines of code as necessary\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the seaborn style to 'darkgrid'\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "# Execute the matplotlib magic function to ensure plots are displayed inline\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo3j358giXMf"
      },
      "source": [
        "## Part 1: Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4vC9VESiXMf"
      },
      "source": [
        "In Part 1 we will try to predict a real value home sale price using several models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "aK2Ou1CGiXMf",
        "outputId": "671da5cb-dff7-4c58-fd30-511718527365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "       SqFtTotLiving_x1000  SqFtLot_x1000     Bedrooms\n",
            "count          1000.000000    1000.000000  1000.000000\n",
            "mean              1.972377       7.456591     3.337000\n",
            "std               0.821994       3.727398     0.907885\n",
            "min               0.620000       0.746000     0.000000\n",
            "25%               1.340000       5.000000     3.000000\n",
            "50%               1.840000       7.181000     3.000000\n",
            "75%               2.460000       9.284750     4.000000\n",
            "max               4.700000      19.984000     9.000000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='AdjSalePrice_x100000', ylabel='Count'>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# 2. (4pts) Load and prepare our data.\n",
        "\n",
        "# Read in the csv file ../data/house_sales_subset.csv using pandas read_csv() with default parameter settings\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('./drive/MyDrive/house_sales_subset.csv')\n",
        "\n",
        "# Create a dataframe X which contains these 3 columns from df:\n",
        "#  'SqFtTotLiving_x1000','SqFtLot_x1000','Bedrooms'\n",
        "X = df.loc[:, ['SqFtTotLiving_x1000','SqFtLot_x1000','Bedrooms']]\n",
        "\n",
        "# Create a series y_r which contains only the column AdjSalePrice_x100000\n",
        "#    Note: the '_r' is for our regression target\n",
        "y_r = df[\"AdjSalePrice_x100000\"]\n",
        "\n",
        "# Check that X and y_r is the correct shape\n",
        "assert X.shape == (1000,3)\n",
        "assert y_r.shape == (1000,)\n",
        "\n",
        "# To confirm that all features of X are similar in scale display the .describe() of X\n",
        "print(X.describe())\n",
        "\n",
        "# To get a sense of the distribution of the target, plot a histogram of y_r using sns.histplot()\n",
        "sns.histplot(y_r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUjWuJsCiXMf",
        "outputId": "407e7b96-531d-4c70-e895-29568f56ed24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "proportion of data in test set: 0.20\n"
          ]
        }
      ],
      "source": [
        "# 3. (3pts) Create a held-aside set\n",
        "\n",
        "# Import train_test_split from sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split X and y_r into 80% train and 20% test using train_test_split\n",
        "#   Use random_state=123 for grading consistency.\n",
        "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X, y_r, test_size = 0.2, random_state = 123)\n",
        "\n",
        "# Print out the the length of y_test_r divided by the length y_r  to confirm our test set size.\n",
        "print(f'proportion of data in test set: {len(y_test_r)/len(y_r):0.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LuDi9QaiXMg"
      },
      "source": [
        "### Part 1.1 Baseline Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whJUlCJWiXMg",
        "outputId": "bca6e760-5c26-451b-e9be-5d0bdff4fbc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dummy training set R^2: 0.00\n"
          ]
        }
      ],
      "source": [
        "# 4. (3pts) Create a DummyRegressor and fit on the training set.\n",
        "\n",
        "# Import the DummyRegressor model from sklearn \n",
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "# Instantiate a DummyRegessor model with strategy=\"mean\" \n",
        "dummy_r = DummyRegressor(strategy = 'mean')\n",
        "\n",
        "# Train the DummyRegressor on the regression training set\n",
        "dummy_r.fit(X_train_r, y_train_r)\n",
        "\n",
        "# Calculate and print the training set R^2 score of the DummyRegressor\n",
        "dummy_r_training_r2 = dummy_r.score(X_train_r, y_train_r)\n",
        "\n",
        "print(f'dummy training set R^2: {dummy_r_training_r2:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A03txJgciXMg"
      },
      "source": [
        "### Part 1.2 Linear Regression and Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LOgEIZmiXMg",
        "outputId": "7b85e24b-3dda-4510-ccda-ac2c652359c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr training set R^2: 0.53\n"
          ]
        }
      ],
      "source": [
        "# 5. (4pts) Train a Linear Regression model and calculate training set R^2.\n",
        "\n",
        "# Import the LinearRegression model from sklearn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Instantiate a LinearRegression model with default arguments and fit on the training set\n",
        "lr = LinearRegression().fit(X_train_r, y_train_r)\n",
        "\n",
        "# Calculate and print the training set R^2 of the LinearRegression model\n",
        "lr_training_r2 = lr.score(X_train_r, y_train_r)\n",
        "\n",
        "print(f'lr training set R^2: {lr_training_r2:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yDY_zN2iXMg",
        "outputId": "fd2d377a-ea24-47dd-d9f7-569f34ac8d3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.48, 0.58, 0.5 , 0.44, 0.58])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# 6. (2pts) Use 5-fold Cross Validation to get a sense of variation \n",
        "#    of Liner Regression R^2 performance on the training set.\n",
        "\n",
        "# Import cross_val_score from sklearn.\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Generate 5-fold cross-validation R^2 scores \n",
        "#    for a LinearRegression model with default arguments \n",
        "#    on the training set\n",
        "lr_cv_scores = cross_val_score(LinearRegression(), X_train_r, y_train_r, cv = 5)\n",
        "\n",
        "# Print out the R^2 scores found by cross_val_score\n",
        "np.round(lr_cv_scores,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_femO_jPiXMg",
        "outputId": "aa89803e-7c99-43f7-f201-2a0f64356123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr mean cv r2: 0.52 +- 0.11\n"
          ]
        }
      ],
      "source": [
        "# 7. (1pts) Calculate mean cv R^2 score +- 2 std. deviations\n",
        "\n",
        "# Calculate the mean cross validation score using the scores created above\n",
        "lr_cv_mean = np.mean(lr_cv_scores)\n",
        "\n",
        "# Calculate 2 standard deviations of the cross validation scores\n",
        "lr_cv_2std = 2 * np.std(lr_cv_scores)\n",
        "\n",
        "# Print out the mean R^2 +- 2 standard variations for the LinearRegression model\n",
        "print(f'lr mean cv r2: {lr_cv_mean:.2f} +- {lr_cv_2std:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2okR_J2iXMg"
      },
      "source": [
        "### Part 1.3 Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkrqMrkniXMh",
        "outputId": "c9c3994f-3751-477a-bd46-3abe1a30ee05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dummy test R2 : -0.01\n",
            "   lr test R2 :  0.47\n"
          ]
        }
      ],
      "source": [
        "# 8. (2pts) Evaluate performance of our trained DummyRegressor and LinearRegression model on the test set.\n",
        "\n",
        "# Calculate R^2 on the test set using the previously trained models\n",
        "dummy_r_test_r2 = dummy_r.score(X_test_r, y_test_r)\n",
        "\n",
        "lr_test_r2 = lr.score(X_test_r, y_test_r)\n",
        "\n",
        "print(f'dummy test R2 : {dummy_r_test_r2: .2f}')\n",
        "print(f'   lr test R2 : {lr_test_r2: .2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXrhk3RpiXMh"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJL64Nq9iXMh"
      },
      "source": [
        "## Part 2: Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF24NpEziXMh"
      },
      "source": [
        "Here we build several models to classify low vs. high adjusted sales price, creating a validation curve and performing grid search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHb-aMEBiXMh"
      },
      "source": [
        "### Create Classification Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0pzaBtuiXMh",
        "outputId": "cfd32772-1fe6-4906-f24f-1bb08020c99e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# To reuse the same dataset, we'll first create a binary target for \n",
        "#    classification by thresholding at the mean of our AdjSalePrice\n",
        "\n",
        "# The classes are:\n",
        "#    Low AdjSalePrice  = 0\n",
        "#    High AdjSalePrice = 1\n",
        "\n",
        "y_c = (df.AdjSalePrice_x100000 > df.AdjSalePrice_x100000.mean()).astype(int)\n",
        "\n",
        "# Print out the unique labels and note it's 0,1 or binary classification\n",
        "y_c.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpuMIFvgiXMh"
      },
      "source": [
        "### Part 2.1 Create a Held-Aside Aet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPcif6FIiXMh",
        "outputId": "2be6b456-bc07-4258-ffa5-a52189ddda98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "proportion of low values: 0.59\n"
          ]
        }
      ],
      "source": [
        "# 9. (3pts) Create a training and test/held-aside set\n",
        "\n",
        "# Split into 80% train and 20% test using train_test_split \n",
        "#    Use the new y_c target and the same X we used for regression\n",
        "#    Stratify according to y_c so class proportions are the same in train and test\n",
        "#    Use random_state=123 for reproducibility\n",
        "#    Save the result into the variables X_train_c,X_test_c,y_train_c,y_test_c\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X, y_c, test_size = 0.2, stratify=y_c, random_state = 123)\n",
        "\n",
        "# Print out the proportion of Low values (label of 0) in y_c\n",
        "print(f'proportion of low values: {np.mean(y_c == 0):0.2f}')\n",
        "\n",
        "# Assert that train and test have similar class proportions.\n",
        "# Find the proportion of Low (0) values in both y_train_c and y_test_c and \n",
        "#    assert that the absolute difference of these proportions is less than .01\n",
        "assert abs((y_train_c == 0).mean() - (y_test_c == 0).mean()) < 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj74h9w-iXMh"
      },
      "source": [
        "### Part 2.2 Measure baseline performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rr5bCgiiXMh",
        "outputId": "20a22c8c-aee5-45d1-d8d2-28f563d09d28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dummy training set accuracy: 0.59\n"
          ]
        }
      ],
      "source": [
        "# 10. (2pts)  Create a Dummy Classifier and confirm the expected performance on the training set.\n",
        "\n",
        "# Import DummyClassifier from sklearn\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "# Instantiate and a DummyClassifier with strategy=\"most_frequent\" and fit on the the training set\n",
        "dummy_c = DummyClassifier(strategy = 'most_frequent').fit(X_train_c, y_train_c)\n",
        "\n",
        "# Print the trained DummyClassifier accuracy on the training set.\n",
        "# It should match the proportion of low values we saw above.\n",
        "print(f'dummy training set accuracy: {dummy_c.score(X_train_c, y_train_c):.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhrvwhSwiXMi"
      },
      "source": [
        "### Part 2.3  Logistic Regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MktVKq_HiXMi",
        "outputId": "2bd70c8e-2b91-455b-b360-0c7d0c0083ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logr mean cv accuracy: 0.81\n"
          ]
        }
      ],
      "source": [
        "# 11. (3pts) It's good practice to start with a \"simple\" model.\n",
        "#     Train and calculate 5-fold cv training set accuracy for a Logistic Regression Classifier.\n",
        "\n",
        "# Import LogisticRegression from sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Generate 5-fold cross validation accuracy on the training set\n",
        "#    using LogisticRegression with default hyperparameters\n",
        "#    store as logr_cvscores\n",
        "logr_cv_scores = cross_val_score(LogisticRegression(),X_train_c,y_train_c)\n",
        "\n",
        "# Print out the mean cv accuracy for the LogisticRegression model\n",
        "print(f'logr mean cv accuracy: {np.mean(logr_cv_scores):0.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ88Z7pjiXMi"
      },
      "source": [
        "### Part 2.4 GradientBoosting model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDbaQA9iiXMi",
        "outputId": "45543a1d-0538-4d20-f91d-f3fae35820f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gbc mean cv accuracy: 0.80 +- 0.01\n"
          ]
        }
      ],
      "source": [
        "# 12. (4pts) Now let's try a more complex model.\n",
        "#     Train and calculate 5-fold cv accuracy \n",
        "#     for a GradientBoosting model using the training set.\n",
        "\n",
        "# Import the GradientBoostingClassifier model from sklearn\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Calculate 5-fold cv training set accuracy scores for a GradientBoostingClassifier\n",
        "#   with 50 trees and max_depth=2\n",
        "#   To speed up training also set n_jobs=-1 in the cross_val_score (use one core for each fold)\n",
        "gbc_cv_scores = cross_val_score(GradientBoostingClassifier(n_estimators = 50, max_depth = 2), X_train_c, y_train_c, cv = 5, n_jobs = -1)\n",
        " \n",
        "# Calculate mean cv accuracy\n",
        "gbc_cv_mean = np.mean(gbc_cv_scores)\n",
        "\n",
        "# Calculate 2 standard deviations for the cv scores\n",
        "gbc_cv_2std = 2*np.std(gbc_cv_scores)\n",
        "\n",
        "print(f'gbc mean cv accuracy: {gbc_cv_mean:.2f} +- {gbc_cv_2std:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzDNHzFSiXMi"
      },
      "source": [
        "### Part 2.5 GradientBoosting and Validation Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "m2nAdfm0iXMi",
        "outputId": "08537991-c10b-4374-c965-2533b630a9c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "max_depth            1     2     3     5     10\n",
              "mean_train_scores  0.81  0.84  0.87  0.95  0.99\n",
              "mean_test_scores   0.79  0.81  0.81  0.79  0.77"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d75317c-6240-43e6-9150-6fef65312e5d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>max_depth</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>5</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean_train_scores</th>\n",
              "      <td>0.81</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_test_scores</th>\n",
              "      <td>0.79</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.77</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d75317c-6240-43e6-9150-6fef65312e5d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d75317c-6240-43e6-9150-6fef65312e5d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d75317c-6240-43e6-9150-6fef65312e5d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# 13. (5pts) Let's investigate how the depth of trees (max_depth) affects performance.\n",
        "#     Generate a validation curve for tree depths in the GradientBoosting model.\n",
        "\n",
        "# Import the validation_curve function from sklearn\n",
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "# In the GradientBoostingClassifier model, the depth of trees is set via max_depth\n",
        "# Here we'll try the depths 1,2,3,5,10\n",
        "depths = [1,2,3,5,10]\n",
        "\n",
        "# Generate the train_scores and test_scores for max_depth at different max_depths\n",
        "#   Use the validation_curve function\n",
        "#   Use a GradientBoostingClassiier with 50 trees\n",
        "#   Use our training set X_train_c, y_train_c\n",
        "#   Use the 'max_depth' parameter\n",
        "#   Use the depths list created above as the parameter range\n",
        "#   Use 3-fold cross validation (reducing to 3 to speed things up)\n",
        "#   Use accuracy as the scoring metric\n",
        "#   Store the results in train_scores,test_scores\n",
        "train_scores,test_scores = validation_curve(GradientBoostingClassifier(n_estimators = 50), \n",
        "                                             param_name = 'max_depth', param_range = depths,\n",
        "                                             X = X_train_c, y = y_train_c, cv = 3, scoring = 'accuracy')\n",
        "\n",
        "# train_scores and test_scores each contain a 2-D array of values\n",
        "#   For each depth (rows) there are 3 scores (columns), one for each fold\n",
        "#   Take the mean for each depth across folds (columns, axis=1) \n",
        "#      and store in mean_train_scores and mean_test_scores\n",
        "mean_train_scores = np.mean(train_scores, axis = 1)\n",
        "mean_test_scores = np.mean(test_scores, axis = 1)\n",
        "\n",
        "# We should get 10 values between 0 and 1\n",
        "# Note that as depth increases, both train and test accuracy go up and then begin to diverge\n",
        "pd.DataFrame([mean_train_scores.round(2),mean_test_scores.round(2)],\n",
        "             columns=pd.Series(depths,name='max_depth'),\n",
        "             index=['mean_train_scores','mean_test_scores'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "21RbWELSiXMi",
        "outputId": "a1f16c84-1eda-46e0-89bf-467e7f24db21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'mean accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# 14. (4pts) Plot the validation curve\n",
        "\n",
        "# Plot mean_train_scores and mean_test_scores on the same plot\n",
        "#    create an axis to plot on using subplots, with figsize=(6,4)\n",
        "#    plot two lines using ax.plot()\n",
        "#      each with \"depths\" on the x-axis\n",
        "#      one for mean_train_scores on the y-axis with label \"train\"\n",
        "#      one for mean_test_scores on the y-axis with label \"test\"\n",
        "#    add a legend using ax.legend()\n",
        "#    label the x-axis as \"max_depth\" and the y-axis as \"mean accuracy\"\n",
        "# Note: use as many lines of code as necessary\n",
        "fig, ax = plt.subplots(1, 1, figsize = (6, 4))\n",
        "ax.plot(depths, mean_train_scores, label = 'train')\n",
        "ax.plot(depths, mean_test_scores, label = 'test')\n",
        "ax.legend()\n",
        "ax.set_xlabel('max_depths')\n",
        "ax.set_ylabel('mean accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lktrti3iXMi"
      },
      "source": [
        "### Part 2.6 GradientBoosting and Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXLooe1niXMi",
        "outputId": "a16d2666-f18c-4180-db89-02d5f5bae651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gbc best hyperparams      : {'max_depth': 3, 'n_estimators': 50}\n",
            "gbc best mean cv accuracy : 0.81\n"
          ]
        }
      ],
      "source": [
        "# 15. (4pts) Above we're looking at tuning a single hyperparameter (max_depth).\n",
        "#     Now let's tune two hyperparameters at the same time.\n",
        "#     Perform 3-fold cross validated grid search over number of trees and tree depth.\n",
        "\n",
        "# Import GridSearchCV from sklearn\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create the grid of parameters to test\n",
        "#   The parameter settings to try are \n",
        "#   'n_estimators':[10,50,100,200],'max_depth':[1,2,3,5,10]\n",
        "params = {'n_estimators': [10, 50, 100, 200], 'max_depth': [1, 2, 3, 5, 10]}\n",
        "\n",
        "# Instantiate and fit GridSearchCV on the classification training set\n",
        "#   Use GradientBoostingClassifier with default arguments \n",
        "#   Use 3-folds\n",
        "#   Use default scoring (accuracy)\n",
        "#   Use refit=True (default) so the model is retrained on the entire training set\n",
        "#   Set n_jobs=-1 to use all cores\n",
        "gbc_gscv = GridSearchCV(GradientBoostingClassifier(), cv = 3, param_grid = params, refit = True, n_jobs = -1).fit(X_train_c, y_train_c)\n",
        "# Print out the best the best hyperparameter setting found (best_params_) \n",
        "#    and the mean accuracy they produced (best_score_)\n",
        "print(f'gbc best hyperparams      : {gbc_gscv.best_params_}')\n",
        "print(f'gbc best mean cv accuracy : {np.mean(gbc_gscv.best_score_):.2f}')\n",
        "\n",
        "# Note that you may get different answers on different runs due to \n",
        "#   the random cv splits used at each grid point"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbXhr04_iXMi"
      },
      "source": [
        "### Part 2.7 Evaluate on Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE8M34UliXMj",
        "outputId": "54793871-a4a1-4454-d143-a1212b387d31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best model found: GradientBoostingClassifier\n",
            "logr test acc : 0.82\n",
            "gbc  test acc : 0.84\n"
          ]
        }
      ],
      "source": [
        "# 16. (4pts) Evaluate the best model on the test set\n",
        "\n",
        "# Which of our models has the highest training set cv accuracy?\n",
        "#   (GradientBoostingClassifier or LogisticRegression?)\n",
        "print('best model found: GradientBoostingClassifier')\n",
        "\n",
        "# To see how each of our models would generalize to new data,\n",
        "#     calculate the **test set** accuracy for each of our trained models\n",
        "\n",
        "# First, instantiate and train a new LogisticRegression model with default settings on the training set.\n",
        "# Note that, while we did train a LogisticRegression model several times when \n",
        "#  calculating the cross-validation accuracy, we never trained it on the full training set\n",
        "logr = LogisticRegression().fit(X_train_c, y_train_c)\n",
        "\n",
        "# Find the test set accuracy of both of our trained models\n",
        "# Recall that since we used refit=True when doing grid search\n",
        "#  on the GradientBoostingClassifier, we can use gbc_gscv.score() without retraining\n",
        "logr_test_acc = logr.score(X_test_c, y_test_c)\n",
        "gbc_test_acc = gbc_gscv.score(X_test_c, y_test_c)\n",
        "\n",
        "print(f'logr test acc : {logr_test_acc:.2f}')\n",
        "print(f'gbc  test acc : {gbc_test_acc:.2f}')\n",
        "\n",
        "# TO THINK ABOUT, BUT DON'T NEED TO ANSWER:\n",
        "# Did the model we chose have the best test set performance?\n",
        "# Is it guaranteed that the model with the best cv scores on the training set has the best test set score?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
